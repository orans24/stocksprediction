{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATATEST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1sAY8MlqPvK7Xgk9alHNvIcOOaF4I9dna",
      "authorship_tag": "ABX9TyNlwBmt273VkWm1Wb+n30F+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/orans24/799b27e17b22ae43b2aec3a6456d3cf4/datatest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_A9lfK396Y"
      },
      "source": [
        "# drafts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hb8Ok9MTI79"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItEafApN2Pq_"
      },
      "source": [
        "# the final code that need to run for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJB5h2mzdl9M"
      },
      "source": [
        "#run the prediction\n",
        "!pip install yfinance\n",
        "!pip install pandas_market_calendars\n",
        "!pip install trading_calendars\n",
        "!pip install pytz\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import pytz\n",
        "import trading_calendars as tc\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from mlxtend.preprocessing import minmax_scaling\n",
        "from datetime import datetime\n",
        "import pandas_market_calendars as mcal\n",
        "with tf.device('/device:GPU:0'):\n",
        "  clear_output()\n",
        "  def prediction(siu):\n",
        "    np.seterr(divide='ignore', invalid='ignore')\n",
        "    stocksnames=siu  #['AAPL','MSFT','FB','GOOGL']\n",
        "    predictionstocks={}\n",
        "    trends={};\n",
        "    k=-1\n",
        "    for sn in stocksnames:\n",
        "      k=k+1\n",
        "      stockssortedin = {};\n",
        "      stockssortedout = {};\n",
        "      mam = {}\n",
        "      inputnotorder = [];\n",
        "      normalhelp = [];\n",
        "      vol = [];\n",
        "      stockname = sn\n",
        "      stock = yf.Ticker(stockname)\n",
        "      maxdate = dt.datetime.now()\n",
        "      max1 = str(maxdate)\n",
        "      max1 = max1.split(' ')\n",
        "      max = max1[0]\n",
        "      min = '2021-01-01'\n",
        "      data = yf.download(stockname, start=min, end=max)\n",
        "      inputnotorder = data.to_numpy()\n",
        "      inputnotorder = inputnotorder\n",
        "      snp = yf.download('^GSPC', start=min, end=max)  # 1927\n",
        "      inputnotorder1 = snp.to_numpy()\n",
        "      djons = yf.download('^DJI', start=min, end=max)  # 1992-01-02\n",
        "      inputnotorder2 = djons.to_numpy()\n",
        "      nasdaq = yf.download('^IXIC', start=min, end=max)  # 1971\n",
        "      inputnotorder3 = nasdaq.to_numpy()\n",
        "      russ = yf.download('^RUT', start=min, end=max)  # 1987\n",
        "      inputnotorder4 = russ.to_numpy()\n",
        "      inputarr = [inputnotorder1, inputnotorder2, inputnotorder3, inputnotorder4]\n",
        "      r1 = len(data)\n",
        "      normalhelp = inputnotorder[r1-25:r1, 0:4].astype(np.float32)\n",
        "      mini = np.min(normalhelp)\n",
        "      maxi = np.max(normalhelp)\n",
        "      mam[0] = [maxi, mini]\n",
        "      normalhelp = (normalhelp - mini) / (maxi - mini)\n",
        "      normalhelp = np.nan_to_num(normalhelp, nan=0.5, posinf=1, neginf=0)\n",
        "      vol = inputnotorder[r1-25:r1, 4].astype(np.float32)\n",
        "      vmin = np.min(vol)\n",
        "      vmax = np.max(vol)\n",
        "      vol = (vol - vmin) / (vmax - vmin)\n",
        "      vol = np.nan_to_num(vol, nan=0.5, posinf=1, neginf=0)\n",
        "      normalhelp = np.insert(normalhelp, 4, vol, axis=1)\n",
        "      for arr in inputarr:\n",
        "        normalhelp1 = arr[r1-25:r1, 0:4].astype(np.float32)\n",
        "        mini = np.min(normalhelp1)\n",
        "        maxi = np.max(normalhelp1)\n",
        "        normalhelp1 = (normalhelp1 - mini) / (maxi - mini)\n",
        "        normalhelp1 = np.nan_to_num(normalhelp1, nan=0.5, posinf=1, neginf=0)\n",
        "        vol = arr[r1-25:r1, 5].astype(np.float32)\n",
        "        vmin = np.min(vol)\n",
        "        vmax = np.max(vol)\n",
        "        vol = (vol - vmin) / (vmax - vmin)\n",
        "        vol = np.nan_to_num(vol, nan=0.5, posinf=1, neginf=0)\n",
        "        normalhelp1 = np.insert(normalhelp1, 4, vol, axis=1)\n",
        "        normalhelp = np.append(normalhelp,normalhelp1,axis=1)\n",
        "      stockssortedin[0] = normalhelp[0:25, :]\n",
        "      x = list(stockssortedin.values())\n",
        "      mm = list(mam.values())\n",
        "      z1 = np.expand_dims(x[0], axis=0)\n",
        "      model = tf.keras.models.load_model('/content/drive/MyDrive/PYTHON APP/mymodels400epoch/'+sn+'model')\n",
        "      p = model(z1)\n",
        "      maxi, mini = mm[0]\n",
        "      p = p.numpy()\n",
        "      p = (p * (maxi - mini)) + mini\n",
        "      l = z1[0, 24, 3]\n",
        "      l = (l * (maxi - mini)) + mini\n",
        "      l1 = z1[0, :, 3]\n",
        "      l1 = (l1 * (maxi - mini)) + mini\n",
        "      if l == 0:\n",
        "        break\n",
        "      trendprediction = ((p[0, 9, 0] - l) / (l)) * 100\n",
        "      predictionstocks[stocksnames[k]] = np.concatenate((l1, p), axis=None)\n",
        "      trends[stocksnames[k]] = trendprediction\n",
        "    yiyi=pd.DataFrame(trends,index=[1],columns=stocksnames)\n",
        "    today = dt.date.today()\n",
        "    nys = tc.get_calendar(\"NASDAQ\")\n",
        "    pas=list(nys.sessions_window(pd.Timestamp(nys.previous_close(pd.Timestamp(today)).strftime('%Y-%m-%d'), tz=pytz.UTC),-25).strftime('%m-%d'))\n",
        "    fut=list(nys.sessions_window(pd.Timestamp(nys.previous_close(pd.Timestamp(today)).strftime('%Y-%m-%d'), tz=pytz.UTC),9).strftime('%m-%d'))\n",
        "    dates=pas+fut[1:10]\n",
        "    yaya=pd.DataFrame(predictionstocks,index=dates,columns=stocksnames)\n",
        "    axes=yaya.plot(figsize=(25,10),subplots=True,grid=True,sharex=False)\n",
        "    z=0\n",
        "\n",
        "    for s in stocksnames:\n",
        "      maxsp=yaya.loc[fut,s].max()\n",
        "      minsp=yaya.loc[fut,s].min()\n",
        "      maxdat=datetime.strptime(yaya.loc[fut,s].idxmax(),'%m-%d').strftime('%m-%d')\n",
        "      mindat=datetime.strptime(yaya.loc[fut,s].idxmin(),'%m-%d').strftime('%m-%d')\n",
        "      ddt=[mindat,maxdat]\n",
        "      ssp=[minsp,maxsp]\n",
        "      yoyo=pd.DataFrame(index=dates,columns=[s])\n",
        "      yoyo.loc[mindat,s]=minsp\n",
        "      yoyo.loc[maxdat,s]=maxsp\n",
        "      yoyo.plot(ax=axes[z],grid=True,style=['y^-'])\n",
        "      z=z+1\n",
        "    plt.setp(axes,xticks=np.arange(len(dates)),xticklabels=dates)\n",
        "    yaya.to_csv(r'/content/drive/MyDrive/PYTHON APP/predictions/'+max+'.csv')\n",
        "    yiyi.to_csv(r'/content/drive/MyDrive/PYTHON APP/predictions/trendof' + max + '.csv')\n",
        "    fig=plt.gcf()\n",
        "    fig.savefig('/content/drive/MyDrive/PYTHON APP/predictions/'+max+'.png')\n",
        "    yiyi.plot(figsize=(10,5),kind='bar')\n",
        "    fig=plt.gcf()\n",
        "    fig.savefig('/content/drive/MyDrive/PYTHON APP/predictions/trendof'+max+'.png')\n",
        "  print(\"choose the stocks you want to predict(you can more then one):\")\n",
        "  stlist=widgets.SelectMultiple(options=['AAPL', 'MSFT', 'FB','GOOGL'],description='',disabled=False)\n",
        "  display(stlist)\n",
        "  button = widgets.Button(description='press to predict',disabled=False,button_style='success',tooltip='Click me',icon='check') \n",
        "  display(button)\n",
        "  def foo(a):\n",
        "    v=list(stlist.value)\n",
        "    prediction(v)\n",
        "  button.on_click(foo)\n",
        "  \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_4g8-083Z3J"
      },
      "source": [
        "# training and building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Nt3WGazytD"
      },
      "source": [
        "#building and training net\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.layers import LSTM,Dense,Reshape\n",
        "from numpy import load\n",
        "from sklearn.model_selection import train_test_split\n",
        "with tf.device('/device:GPU:0'):\n",
        "  stocksnames=['AAPL','FB','MSFT','GOOGL']\n",
        "  for sn in stocksnames:\n",
        "    model3=Sequential() \n",
        "    checkpoint_path = \"/content/drive/MyDrive/PYTHON APP/training/cp.ckpt\"\n",
        "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                  save_weights_only=True,\n",
        "                                                  verbose=1)\n",
        "    os.listdir(checkpoint_dir)\n",
        "    \n",
        "    dict_data = load('/content/drive/MyDrive/PYTHON APP/stocksdata/'+sn+'.npz')\n",
        "    dict_data.allow_pickle=True\n",
        "    x1=dict_data['arr_0']\n",
        "    y1=dict_data['arr_1']\n",
        "    x2=x1.tolist()\n",
        "    y2=y1.tolist()\n",
        "    x = list(x2.values())\n",
        "    y = list(y2.values())\n",
        "    x=np.nan_to_num(x,nan=0.5,posinf=1,neginf=0)\n",
        "    y=np.nan_to_num(y,nan=0.5,posinf=1,neginf=0)\n",
        "    x_train4,x_test4,y_train4,y_test4 = train_test_split(x, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42)\n",
        "    model3.add(LSTM(512,input_shape=(25,25),return_sequences=True,activation='tanh',recurrent_activation ='sigmoid'\n",
        "    ,dropout=0.2,recurrent_dropout=0,use_bias=True,unroll=False))\n",
        "    model3.add(LSTM(256,input_shape=(25,25),return_sequences=True,activation='tanh',recurrent_activation ='sigmoid'\n",
        "    ,dropout=0.2,recurrent_dropout=0,use_bias=True,unroll=False))\n",
        "    model3.add(LSTM(128,input_shape=(25,25),return_sequences=False,activation='tanh',recurrent_activation ='sigmoid'\n",
        "    ,dropout=0.2,recurrent_dropout=0,use_bias=True,unroll=False))\n",
        "    model3.add(Dense(10,activation='sigmoid',kernel_initializer=tf.initializers.zeros()))\n",
        "    model3.add(Reshape([10,1]))\n",
        "    model3.compile(loss='mse',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['MeanAbsoluteError'])\n",
        "    model3.fit(x_train4,\n",
        "    y_train4,\n",
        "    epochs=300\n",
        "    ,verbose=1,\n",
        "    validation_data=(x_test4,y_test4),batch_size=32,validation_batch_size=32,callbacks=[cp_callback])\n",
        "    score = model3.evaluate(x_test4,y_test4,\n",
        "    batch_size=32)\n",
        "    model3.save('/content/drive/MyDrive/PYTHON APP/mymodels400epoch/'+sn+'model') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9XPr-f_3CZh"
      },
      "source": [
        "# testing models trends accuracy and subplot presentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrWRCGGvjuKu"
      },
      "source": [
        "#subplot presentation\n",
        "import matplotlib.pyplot as plt\n",
        "fig,(axs1,axs2,axs3) = plt.subplots(3)\n",
        "fig.set_figwidth(20)\n",
        "fig.set_figheight(10)\n",
        "axs1.plot(stockr[0:2500],color = 'red',linestyle='dotted',marker=',', label = 'real price')\n",
        "axs1.plot(stockp[0:2500], color = 'black', label = 'Predicted ')\n",
        "axs2.plot(stockr[2500:5000],color = 'red',marker=',',linestyle='dotted', label = 'real price')\n",
        "axs2.plot(stockp[2500:5000], color = 'black', label = 'Predicted ')\n",
        "axs3.plot(stockr[5000:len(stockp)],color = 'red',marker=',',linestyle='dotted', label = 'real price')\n",
        "axs3.plot(stockp[5000:len(stockp)], color = 'black', label = 'Predicted ')\n",
        "axs1.set_title('first 2500 days')\n",
        "axs2.set_title('2500-5000 days')\n",
        "axs3.set_title('5000 till now')\n",
        "axs1.label_outer()\n",
        "axs2.label_outer()\n",
        "axs3.label_outer()\n",
        "axs1.set(xlabel='days', ylabel='stock price')\n",
        "axs2.set(xlabel='days', ylabel='stock price')\n",
        "axs3.set(xlabel='days', ylabel='stock price')\n",
        "axs1.legend()\n",
        "axs2.legend()\n",
        "axs3.legend()\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bONgeo1zrZl_"
      },
      "source": [
        "#checking trend accuracy\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from numpy import load\n",
        "\n",
        "model=tf.keras.models.load_model('/content/drive/MyDrive/PYTHON APP/mymodels400epoch/APPLmodel')\n",
        "dict_data = load('/content/drive/MyDrive/PYTHON APP/stocksdata/APPL.npz')\n",
        "dict_data.allow_pickle=True\n",
        "x1=dict_data['arr_0']\n",
        "y1=dict_data['arr_1']\n",
        "mm1=dict_data['arr_2']\n",
        "x2=x1.tolist()\n",
        "y2=y1.tolist()\n",
        "mm2=mm1.tolist()\n",
        "x = list(x2.values())\n",
        "y = list(y2.values())\n",
        "mm= list(mm2.values())\n",
        "count=0\n",
        "pretrends={}\n",
        "realtreands={}\n",
        "k={}\n",
        "prestock={}\n",
        "restock={}\n",
        "for j in range(0,len(x)):\n",
        "  z1=np.expand_dims(x[j], axis=0)\n",
        "  f1=model(z1)\n",
        "  p1=f1[0]\n",
        "  p=p1[9,0]\n",
        "  r1=y[j]\n",
        "  r=r1[9]\n",
        "  maxi,mini=mm[j]\n",
        "  p=p.numpy()\n",
        "  p=(p*(maxi-mini))+mini\n",
        "  r=(r*(maxi-mini))+mini\n",
        "  prestock[j]=p\n",
        "  restock[j]=r\n",
        "  l=z1[0,24,3]\n",
        "  l=(l*(maxi-mini))+mini\n",
        "  if l==0:\n",
        "    break\n",
        "  trendprediction=((p-l)/(l))*100\n",
        "  realprediction=((r-l)/(l))*100\n",
        "  pretrends[j]=trendprediction\n",
        "  realtreands[j]=realprediction\n",
        "  if trendprediction>1000:\n",
        "    k[j]=[p,r,l]\n",
        "  if trendprediction>=0:\n",
        "    uppred=1\n",
        "  else:\n",
        "      uppred=0\n",
        "  if realprediction>=0:\n",
        "    upreal=1\n",
        "  else:\n",
        "      upreal=0\n",
        "  acc=uppred+upreal\n",
        "  if acc==2 or acc==0:\n",
        "    count=count+1\n",
        "print('from ',len(x),' accuracy trend are ',count)\n",
        "stockp=list(prestock.values())\n",
        "stockr=list(restock.values())\n",
        "pre=list(pretrends.values())\n",
        "real=list(realtreands.values())\n",
        "f = plt.figure()\n",
        "f.set_figwidth(200)\n",
        "f.set_figheight(10)\n",
        "plt.plot(stockr, 'red',linestyle='dotted',marker=',', label = 'real price')\n",
        "plt.plot(stockp, 'black', label = 'Predicted ')\n",
        "plt.title('real')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "k\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgLOMLx9ZaEu"
      },
      "source": [
        "# create data for training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd45RsbENcgu"
      },
      "source": [
        "#building traning data for stock\n",
        "# building traning data for stock\n",
        "\n",
        "\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from mlxtend.preprocessing import minmax_scaling\n",
        "with tf.device('/device:GPU:0'):\n",
        "    stockssortedin = {};\n",
        "    stockssortedout = {};\n",
        "    mam = {}\n",
        "    inputnotorder = [];\n",
        "    normalhelp = [];\n",
        "    vol = [];\n",
        "    np.seterr(divide='ignore', invalid='ignore')\n",
        "    stocksnames = ['AAPL']\n",
        "    for sn in stocksnames:\n",
        "        stockssortedin = {};\n",
        "        stockssortedout = {};\n",
        "        mam = {}\n",
        "        inputnotorder = [];\n",
        "        normalhelp = [];\n",
        "        vol = [];\n",
        "        stockname = sn\n",
        "        stock = yf.Ticker(stockname)\n",
        "        data = stock.history(period=\"max\")\n",
        "        mindate = data.index.min()\n",
        "        maxdate = data.index.max()\n",
        "        min1 = str(mindate)\n",
        "        min1 = min1.split(' ')\n",
        "        min = min1[0]  # '1992-01-02'\n",
        "        max1 = str(maxdate)\n",
        "        max1 = max1.split(' ')\n",
        "        max = max1[0]\n",
        "        if min < '1992-01-02':\n",
        "            min = '1992-01-02'\n",
        "            data = yf.download(stockname, start=min, end=max)\n",
        "        inputnotorder = data.to_numpy()\n",
        "        inputnotorder = inputnotorder\n",
        "        snp = yf.download('^GSPC', start=min, end=max)  # 1927\n",
        "        inputnotorder1 = snp.to_numpy()\n",
        "        djons = yf.download('^DJI', start=min, end=max)  # 1992-01-02\n",
        "        inputnotorder2 = djons.to_numpy()\n",
        "        nasdaq = yf.download('^IXIC', start=min, end=max)  # 1971\n",
        "        inputnotorder3 = nasdaq.to_numpy()\n",
        "        russ = yf.download('^RUT', start=min, end=max)  # 1987\n",
        "        inputnotorder4 = russ.to_numpy()\n",
        "        k = 0;\n",
        "        h = 5\n",
        "        inputarr = [inputnotorder1, inputnotorder2, inputnotorder3, inputnotorder4]\n",
        "\n",
        "        r1 = len(data)\n",
        "        for i in range(0, r1):\n",
        "            if i >= r1 - 35:\n",
        "                break\n",
        "            normalhelp = inputnotorder[i:i + 35, 0:4].astype(np.float32)\n",
        "            mini = np.min(normalhelp)\n",
        "            maxi = np.max(normalhelp)\n",
        "            mam[i] = [maxi, mini]\n",
        "            normalhelp = (normalhelp - mini) / (maxi - mini)\n",
        "            normalhelp = np.nan_to_num(normalhelp, nan=0.5, posinf=1, neginf=0)\n",
        "            vol = inputnotorder[i:i + 35, 4].astype(np.float32)\n",
        "            vmin = np.min(vol)\n",
        "            vmax = np.max(vol)\n",
        "            vol = (vol - vmin) / (vmax - vmin)\n",
        "            vol = np.nan_to_num(vol, nan=0.5, posinf=1, neginf=0)\n",
        "            normalhelp = np.insert(normalhelp, 4, vol, axis=1)\n",
        "            for arr in inputarr:\n",
        "                normalhelp1 = arr[i:i + 35, 0:4].astype(np.float32)\n",
        "                mini = np.min(normalhelp1)\n",
        "                maxi = np.max(normalhelp1)\n",
        "                normalhelp1 = (normalhelp1 - mini) / (maxi - mini)\n",
        "                normalhelp1 = np.nan_to_num(normalhelp1, nan=0.5, posinf=1, neginf=0)\n",
        "                vol = arr[i:i + 35, 5].astype(np.float32)\n",
        "                vmin = np.min(vol)\n",
        "                vmax = np.max(vol)\n",
        "                vol = (vol - vmin) / (vmax - vmin)\n",
        "                vol = np.nan_to_num(vol, nan=0.5, posinf=1, neginf=0)\n",
        "                normalhelp1 = np.insert(normalhelp1, 4, vol, axis=1)\n",
        "                normalhelp = np.append(normalhelp,normalhelp1,axis=1)\n",
        "                h=h+5\n",
        "            stockssortedin[k] = normalhelp[0:25, :]\n",
        "            stockssortedout[k] = normalhelp[25:35, 3]\n",
        "            k = k + 1\n",
        "        np.savez(stockname, stockssortedin, stockssortedout, mam)\n",
        "\n",
        "print(np.max(stockssortedin.values()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTIwDGkw3uNK"
      },
      "source": [
        "# mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ2lLjgERBSi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}